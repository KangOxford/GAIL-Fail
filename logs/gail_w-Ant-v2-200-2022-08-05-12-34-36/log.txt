2022-08-05 12:36:15.812515 - utils/flags.py:260 - log_dir = logs/gail_w-Ant-v2-200-2022-08-05-12-34-36
2022-08-05 12:36:16.842532 - gail/utils/replay_buffer.py:86 - Load dataset from /workspace/GAIL-Fail/dataset/sac/Ant-v2
2022-08-05 12:36:18.924822 - gail/main.py:80 - Expert Reward 4070.095332
2022-08-05 12:36:19.035829 - gail/main.py:84 - Original dataset size 3000
2022-08-05 12:36:19.040593 - gail/main.py:86 - Subsampled dataset size 3000
2022-08-05 12:36:19.040757 - gail/main.py:87 - np random: 864 random : 786
2022-08-05 12:36:19.041059 - gail/main.py:91 - Sampled obs: 0.0354, acs: -0.0459
2022-08-05 12:36:20.412135 - lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-08-05 12:36:23.230586 - gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-08-05 12:36:23.232490 - gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 6.57785654e-01  9.47473288e-01 -2.19117794e-02 -1.41637191e-01
   2.41327509e-01 -1.62708357e-01  6.64058506e-01 -5.04970789e-01
  -5.34117281e-01  1.49354592e-01 -6.93979800e-01  4.66125011e-01
   5.54298878e-01  4.18425608e+00 -2.72123426e-01 -2.97389226e-03
   5.46980128e-02 -2.24658456e-02 -2.97487285e-02 -1.10163175e-01
   4.20587556e-03  1.03724813e-02 -2.04264037e-02  7.23826736e-02
  -7.79535016e-03  1.65822962e-03  1.86213199e-02  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  8.87130350e-02
  -6.80284128e-02 -6.62214458e-02  5.81009947e-02 -7.27041671e-03
   9.27375108e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  5.69573678e-02  5.89232072e-02  1.62900053e-02
  -5.55793755e-02  1.47131197e-02  5.93333319e-02  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.48398414e-01
  -1.27116498e-02  5.09799905e-02  4.84413207e-02 -2.86797080e-02
   1.48831308e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00 -5.09244855e-03 -8.88925139e-03  4.07147035e-03
   2.64643575e-03  1.31719513e-03  9.99999978e-03]] 
 scale:[[0.10038217 0.02975036 0.05683243 0.08269629 0.1120714  0.42721084
  0.17675936 0.08019576 0.04551525 0.42459542 0.22779518 0.20099343
  0.13546911 0.9592246  0.82011193 0.973432   1.2727388  2.0668283
  1.2254533  6.311867   2.492494   1.0943636  0.7592339  6.288586
  3.57407    1.5957209  1.5894238  0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.2907049  0.2928238  0.29378334
  0.29754704 0.29176813 0.28997144 0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.23486853 0.23516735 0.23338667
  0.23599193 0.23522049 0.23624821 0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.35435402 0.3443248  0.37361518
  0.37567058 0.37041962 0.3547439  0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.09461509 0.0976931  0.09573182
  0.0997695  0.09301171 0.09949706]]
2022-08-05 12:36:24.251642 - gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-08-05 12:36:24.251840 - gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(119, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-08-05 12:36:24.251935 - gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-08-05 12:36:24.368784 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-08-05 12:36:51.926307 - gail/main.py:143 - [Evaluate] iter = 0 episode={ returns = 1004.4934 lengths = 1000 } discounted_episode={ returns = 632.5179 lengths = 1000 } 
2022-08-05 12:36:51.926558 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-08-05 12:36:53.663703 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-08-05 12:36:53.722176 - lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-08-05 12:36:53.766321 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-08-05 12:36:53.821861 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-08-05 12:36:53.969851 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-08-05 12:36:54.316316 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-08-05 12:36:54.350469 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-08-05 12:36:54.421301 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-08-05 12:36:54.516857 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-08-05 12:36:54.666214 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-08-05 12:36:54.733304 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-08-05 12:36:54.763051 - gail/main.py:175 - [TRPO] iter = 1000 dist_mean = 0.0000 dist_std = 1.0000 vf_loss = 0.4154 grad_norm = 0.3830 nat_grad_norm = 0.7175 cg_residual = 0.0000 step_size = 0.3032 reward = 0.0000 fps = 32 mse_loss = 0.2643 
2022-08-05 12:36:56.557642 - gail/main.py:175 - [TRPO] iter = 2000 dist_mean = -0.0043 dist_std = 0.9979 vf_loss = 1.0350 grad_norm = 0.3459 nat_grad_norm = 0.6778 cg_residual = 0.0000 step_size = 0.3386 reward = -0.0000 fps = 31 mse_loss = 0.2654 
2022-08-05 12:36:58.446870 - gail/main.py:175 - [TRPO] iter = 3000 dist_mean = -0.0102 dist_std = 1.0000 vf_loss = 0.6008 grad_norm = 0.3652 nat_grad_norm = 0.7239 cg_residual = 0.0000 step_size = 0.3084 reward = 0.0000 fps = 29 mse_loss = 0.2865 
2022-08-05 12:37:00.227241 - gail/main.py:175 - [TRPO] iter = 4000 dist_mean = -0.0160 dist_std = 0.9970 vf_loss = 0.8587 grad_norm = 0.3859 nat_grad_norm = 0.7479 cg_residual = 0.0000 step_size = 0.3002 reward = 0.0000 fps = 27 mse_loss = 0.2912 
2022-08-05 12:37:01.954651 - gail/main.py:175 - [TRPO] iter = 5000 dist_mean = -0.0203 dist_std = 0.9989 vf_loss = 1.0380 grad_norm = 0.3894 nat_grad_norm = 0.7481 cg_residual = 0.0000 step_size = 0.3055 reward = -0.0000 fps = 26 mse_loss = 0.2971 
2022-08-05 12:37:01.955317 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-08-05 12:37:02.260799 - gail/main.py:202 - [Discriminator] iter = 5000 loss = 1223014.8750 grad_norm = 4500733.5000 grad_penalty = 1223014.7500 regularization = 0.0000 true_logits = 0.0452 fake_logits = 0.2463 true_prob = 0.5112 fake_prob = 0.5549 
