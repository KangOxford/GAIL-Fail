2022-08-05 12:36:22.642061 - utils/flags.py:260 - log_dir = logs/gail_w-Ant-v2-300-2022-08-05-12-34-39
2022-08-05 12:36:24.226531 - gail/utils/replay_buffer.py:86 - Load dataset from /workspace/GAIL-Fail/dataset/sac/Ant-v2
2022-08-05 12:36:25.729633 - gail/main.py:80 - Expert Reward 4070.095332
2022-08-05 12:36:25.816983 - gail/main.py:84 - Original dataset size 3000
2022-08-05 12:36:25.821445 - gail/main.py:86 - Subsampled dataset size 3000
2022-08-05 12:36:25.821575 - gail/main.py:87 - np random: 864 random : 786
2022-08-05 12:36:25.821950 - gail/main.py:91 - Sampled obs: 0.0354, acs: -0.0459
2022-08-05 12:36:26.816436 - lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-08-05 12:36:28.362960 - gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-08-05 12:36:28.365030 - gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 6.57785654e-01  9.47473288e-01 -2.19117794e-02 -1.41637191e-01
   2.41327509e-01 -1.62708357e-01  6.64058506e-01 -5.04970789e-01
  -5.34117281e-01  1.49354592e-01 -6.93979800e-01  4.66125011e-01
   5.54298878e-01  4.18425608e+00 -2.72123426e-01 -2.97389226e-03
   5.46980128e-02 -2.24658456e-02 -2.97487285e-02 -1.10163175e-01
   4.20587556e-03  1.03724813e-02 -2.04264037e-02  7.23826736e-02
  -7.79535016e-03  1.65822962e-03  1.86213199e-02  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  8.87130350e-02
  -6.80284128e-02 -6.62214458e-02  5.81009947e-02 -7.27041671e-03
   9.27375108e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  5.69573678e-02  5.89232072e-02  1.62900053e-02
  -5.55793755e-02  1.47131197e-02  5.93333319e-02  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.48398414e-01
  -1.27116498e-02  5.09799905e-02  4.84413207e-02 -2.86797080e-02
   1.48831308e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
   0.00000000e+00 -5.09244855e-03 -8.88925139e-03  4.07147035e-03
   2.64643575e-03  1.31719513e-03  9.99999978e-03]] 
 scale:[[0.10038217 0.02975036 0.05683243 0.08269629 0.1120714  0.42721084
  0.17675936 0.08019576 0.04551525 0.42459542 0.22779518 0.20099343
  0.13546911 0.9592246  0.82011193 0.973432   1.2727388  2.0668283
  1.2254533  6.311867   2.492494   1.0943636  0.7592339  6.288586
  3.57407    1.5957209  1.5894238  0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.2907049  0.2928238  0.29378334
  0.29754704 0.29176813 0.28997144 0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.23486853 0.23516735 0.23338667
  0.23599193 0.23522049 0.23624821 0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.35435402 0.3443248  0.37361518
  0.37567058 0.37041962 0.3547439  0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.09461509 0.0976931  0.09573182
  0.0997695  0.09301171 0.09949706]]
2022-08-05 12:36:29.247614 - gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-08-05 12:36:29.247824 - gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(119, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-08-05 12:36:29.247937 - gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-08-05 12:36:29.360426 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-08-05 12:36:54.959057 - gail/main.py:143 - [Evaluate] iter = 0 episode={ returns = 998.5880 lengths = 1000 } discounted_episode={ returns = 631.7333 lengths = 1000 } 
2022-08-05 12:36:54.959363 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-08-05 12:36:56.942872 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-08-05 12:36:57.004783 - lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-08-05 12:36:57.050288 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-08-05 12:36:57.068018 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-08-05 12:36:57.251490 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-08-05 12:36:57.730898 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-08-05 12:36:57.812453 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-08-05 12:36:57.838182 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-08-05 12:36:57.927659 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-08-05 12:36:58.131392 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-08-05 12:36:58.218342 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-08-05 12:36:58.242414 - gail/main.py:175 - [TRPO] iter = 1000 dist_mean = -0.0000 dist_std = 1.0000 vf_loss = 0.5087 grad_norm = 0.3246 nat_grad_norm = 0.6888 cg_residual = 0.0000 step_size = 0.3344 reward = 0.0000 fps = 34 mse_loss = 0.2690 
2022-08-05 12:37:00.127360 - gail/main.py:175 - [TRPO] iter = 2000 dist_mean = -0.0044 dist_std = 1.0014 vf_loss = 0.8373 grad_norm = 0.3194 nat_grad_norm = 0.6870 cg_residual = 0.0000 step_size = 0.3405 reward = 0.0000 fps = 32 mse_loss = 0.2616 
2022-08-05 12:37:01.751655 - gail/main.py:175 - [TRPO] iter = 3000 dist_mean = -0.0060 dist_std = 1.0018 vf_loss = 2.1296 grad_norm = 0.3719 nat_grad_norm = 0.7525 cg_residual = 0.0000 step_size = 0.3091 reward = 0.0000 fps = 30 mse_loss = 0.2703 
2022-08-05 12:37:03.545226 - gail/main.py:175 - [TRPO] iter = 4000 dist_mean = -0.0130 dist_std = 0.9968 vf_loss = 1.8447 grad_norm = 0.3862 nat_grad_norm = 0.8299 cg_residual = 0.0000 step_size = 0.2867 reward = 0.0000 fps = 29 mse_loss = 0.2887 
2022-08-05 12:37:05.633321 - gail/main.py:175 - [TRPO] iter = 5000 dist_mean = -0.0053 dist_std = 0.9950 vf_loss = 2.4768 grad_norm = 0.3713 nat_grad_norm = 0.7645 cg_residual = 0.0000 step_size = 0.2989 reward = -0.0000 fps = 27 mse_loss = 0.2849 
2022-08-05 12:37:05.634026 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-08-05 12:37:06.208989 - gail/main.py:202 - [Discriminator] iter = 5000 loss = 860676.0000 grad_norm = 3077292.2500 grad_penalty = 860677.1875 regularization = 0.0000 true_logits = -0.0827 fake_logits = -1.2490 true_prob = 0.4797 fake_prob = 0.2485 
